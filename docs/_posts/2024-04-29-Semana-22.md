---
title: "Semana 22 - Piloto experto cruza ventanas"
categories:
  - Registro Semanal
tags:
  - ROS2
  - Aprendizaje Automático
---

## Índice
- [Índice](#índice)
- [Piloto experto Aerostack2](#piloto-experto-aerostack2)
- [Configuración del entorno](#configuración-del-entorno)
- [Creación del mapa](#creación-del-mapa)
- [Automatización para la obtención del dataset](#automatización-para-la-obtención-del-dataset)
- [Piloto remoto](#piloto-remoto)
- [Prueba de la red neuronal](#prueba-de-la-red-neuronal)

---

## Piloto experto Aerostack2

Aprovechando el proyecto [project_crazyfile_gates](https://github.com/aerostack2/project_crazyflie_gates) y solucionando el fallo de la semana pasada, que se resolvió instalando el paquete [as2_external_object_to_tf](https://github.com/aerostack2/as2_external_object_to_tf), creé un [fork](https://github.com/Adrimapo/project_crazyflie_gates) del repositorio para que contara con más ejemplos mientras desarrollaba el piloto experto para la obtención del dataset.

El piloto experto realiza el ejercicio teniendo los "ojos de Dios" sobre el entorno, sabiendo dónde está cada ventana y su posición exacta, por lo que generar varios circuitos y que siguiera varias ventanas podría ser una tarea bastante tediosa y podría ocupar bastante tiempo. Por lo tanto, se ideó otra manera de generar el dataset.

Siguiendo en la línea de la semana pasada, se podría generar un script que genere un mundo con las posiciones y rotaciones de las ventanas parcialmente aleatorias y hacer que el dron siga a las mismas. De esta manera, si lo combinamos con la automatización que utilizamos en el ejercicio del sigue líneas, podríamos crear un dataset de manera automática.

## Configuración del entorno

Como base para la implementación del piloto experto, se empleó el repositorio `project_crazyflie_gates`. Este repositorio contiene un ejemplo de uso de `Aerostack2`, donde un dron describe una trayectoria circular atravesando dos puertas paralelas. El dron atraviesa estas dos puertas gracias al paquete `as2_external_object_to_tf`, que proporciona las transformaciones de ambas puertas y permite enviar el dron al centro de las mismas.

## Creación del mapa

Una vez terminada la configuración del dron, lo siguiente fue la distribución de ventanas en el mapa. Se creó un script de Python capaz de generar mundos aleatorios con $n$ ventanas para automatizar la generación del dataset. El script elige aleatoriamente entre dos mapas, `empty` o `grass`, y genera las transformaciones de cada puerta. Luego, crea las ventanas para que el dron opere constantemente sin perder de vista la siguiente ventana.

<div style="display: flex; justify-content: center;">

    <figure class="align-center" style="width: 20%;">
        <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post22/map1.png" alt="">
    </figure>

    <figure class="align-center" style="width: 20%;">
        <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post22/map2.png" alt="">
    </figure>

    <figure class="align-center" style="width: 20%;">
        <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post22/map3.png" alt="">
    </figure>

    <figure class="align-center" style="width: 20%;">
        <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post22/map4.png" alt="">
    </figure>

</div>

## Automatización para la obtención del dataset

Se creó un nodo capaz de traducir las velocidades comandadas por el control de posición al control creado en el ejercicio anterior. Las velocidades solo se graban cuando superan un umbral determinado por una velocidad mínima. Los scripts de automatización ejecutan en segundo plano la simulación, el sistema de Aerostack y el grabador de ROSbags, dejando en primer plano la misión del dron. Una vez finalizada la misión, se espera un tiempo determinado y se inicia una nueva ejecución con un nuevo mapa aleatorio.

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post22/resultadosEntrenamiento.png" alt="">
  <figcaption>Visualización en Rviz</figcaption>
</figure>

## Piloto remoto

Se terminó la distribución de controles del mando, dejando el siguiente resultado:

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post22/controller.png" alt="">
  <figcaption>Controlador</figcaption>
</figure>

Esto nos permitirá grabar datasets con mucha más facilidad, además de probar el rendimiento de la red neuronal al atravesar ventanas de una manera mucho más dinámica.

## Prueba de la red neuronal

La semana pasada dejamos una red neuronal entrenando, dando el siguiente resultado:

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post22/resultadosEntrenamiento.png" alt="">
  <figcaption>Resultados del entrenamiento</figcaption>
</figure>

Al ejecutar el programa se puede ver cómo el dron no sigue adecuadamente las puertas aunque muestra comportamientos de esquivar las mismas a pesar de sus pocas muestras en entrenamiento.

<iframe width="560" height="315" src="https://www.youtube.com/embed/1seFyxNtpYk?si=6o7knEKHjbiQdRF3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
