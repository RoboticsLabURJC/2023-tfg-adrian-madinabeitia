---
title: "Semana 14 - Oversample de dataset"
categories:
  - Registro Semanal
tags:
  - ROS2
  - Aprendizaje Automático
---


## Índice

---

## Cuantificación del error
Lo primero que se hizo esta semana fué cunatificar el error en ambos recorridos, paraesto primero se encuentra el punto mas cercano de la ruta de referencia al primer punto de la ruta a la cual se quiera calcular el error.

Una vez conseguido este punto se recorrerá la segunda ruta y se calculará la distancia euclidea con el punto equivalente de la ruta de referencia. Para evitar errores se añadió una holgura de 5 puntos a la hora de compara puntos de la ruta de referencia. El error será la distancia mínima entre estos 5 puntos y se pasará al siguiente. 

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post14/errorGraphic.png" alt="">
  <figcaption>Error graphic</figcaption>
</figure>

---
---

## Gráfica dataset
Me encontré con una (publicación)[https://www.linkedin.com/feed/update/urn:li:activity:7165418973927333889/] que hablaba sobre la importancia de la normalización del dataset para el correcto aprendizaje, lo que me dió la idea de graficar de distinta manera las velocidades para ver de otra forma la distribución del dataset y así a lo mejor definir de una manera más óptima los labels permitiendo además un mejor análisis del dataset y su distribución.

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post14/newGraphic.png" alt="">
  <figcaption>Error graphic</figcaption>
</figure>

Con esta gráfica podemos ver la distribución de los datos y etiquetas de una manera más clara, además a la hora de sobremuestrar esta gráfica podría ser muy útil. 

La siguiente modificación fue hacer que se mostraran las gráficas en la misma ventana para comparar de una manera mas sencilla:

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post14/newFormat.png" alt="">
  <figcaption>Graphics</figcaption>
</figure>

De esta manera no solo podemos comparar operaciones sobre el dataset si no que podremos comparar varios datasets.

---
---

## Augmentation
Lo siguiente fué aplicar la técnica de [augmentation](https://neptune.ai/blog/data-augmentation-in-python) en el caso de imágenes se suele utilizar:
- Transfomaciones geométricas
- Cambios en el espacio de color
- Filtros de kernel
- Eliminación de partes aleatorias
- Combinación de imágenes
- Cambio de prespectiva
- Deformaciones elásitcas
- Mirroring (Varios tipos de vueltas)

Para la implementación me parecieron interesantes:
- Transformaciones geométricas desplazando lateralmente la imagen para la velocidad angular  y verticalmente para la velocidad lineal.
- Cambios en el espacio de color también es una técnica interesante, sobretodo en contrastes.
- Mirroring, si tenemos una curva, podremos hacer la espejo e invertir la velocidad angular.

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post14/transform1.png" alt="">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post14/transform2.png" alt="">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post14/transform3.png" alt="">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post14/transform4.png" alt="">
</figure>

Ahora graficamos los resultados, podemos ver que algunas columnas se igualan devido a las imagenes espejos, y que enalgunos casos las medidas se centran mas en los límitres que deberían como las velocidades lineales con giro 0. También vemos que los casos mas repetidos se condensan mas pero que tenemos más casos raros a la vez. Esto sin tener en cuenta los cambios de imagen los cuales aquí no podemos añadir como datos ya que solo se tienen en cuenta las velocidades. 

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post14/firstAugmentation.png" alt="">
  <figcaption>First data augmentation</figcaption>
</figure>


---
---

## Pruebas con augmentation dataset
Se procedió a realizar pruebas con el dataset actual por ver si se conseguía completar el circuito pero los resultados fueron negativos. Esto nos da la lección que la distribucción de los datos es crucial y  de tener un buen dataset.