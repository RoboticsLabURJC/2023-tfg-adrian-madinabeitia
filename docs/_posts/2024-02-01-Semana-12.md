---
title: "Semana 12 - Control de velocidad lineal"
categories:
  - Registro Semanal
tags:
  - ROS2
  - Aprendizaje Automático
---

## Índice

---

## Mejora en piloto experto

Anteriormente, teníamos velocidad lineal constante; esta semana mejoramos el piloto experto de tal manera que tuviera velocidad adaptativa.

En vez de conseguir a mano el punto medio para la velocidad angular, se hizo que se consiguiera con funciones de OpenCV, aumentando bastante la frecuencia con la que se procesan las imágenes, dando una frecuencia media de lectura de imagen de 30 Hz y de publicación de velocidades de 100 Hz:

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post12/mejoraFrecuencias.png" alt="">
  <figcaption>Gráficas de frecuencias</figcaption>
</figure>

Para la velocidad angular, se tomaron como referencia las siguientes 2 franjas acompañadas de un PID. La franja superior tiene un peso de 0.6 para aumentar la predicción, mientras que la franja inferior tiene un peso de 0.4 para que el dron trate de mantenerse sobre la línea.

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post12/franjasAngulares.png" alt="">
  <figcaption>Franjas velocidad angular</figcaption>
</figure>

Para la velocidad lineal, se calcula el error a partir del punto lateral más separado del centro. Después se normalizan las medidas respecto al rango de velocidad lineal y se utiliza un PID.

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post12/franjasLineales.png" alt="">
  <figcaption>Franjas velocidad lineal</figcaption>
</figure>

---

## Fallo con ejecución

A la hora de usar timers en ROS, surgió un error. Después de despegar el dron, el callback del timer solo se llama una vez. Si se llama al nodo con el dron despegado, el timer irá bien. Se manejaron las siguientes soluciones:
* Timer desde rclpy: Dio los mismos resultados.
* Multithreading para el despegue: Mismo error.
* Bucle while ROS:OK y llamada a la función con sleep de ROS. El dron baja mucho la frecuencia pero responde.
* Llamar a la función con un while true y llamada a la función: Mejor resultado pero peor forma de código.

La solución se dejó para la semana siguiente debido a que ocupó más tiempo del esperado sin resultados lo suficientemente buenos; de momento, se dejó con timers en el nodo y ejecutando el mismo 2 veces.

---

## Dataset

El siguiente paso consistió en la generación de un nuevo dataset. Se decidió que se utilizarían los circuitos de montreal_line, simple_circuit y montmelo_line como circuitos para entrenamiento en ambos sentidos. Para test se dejó el circuito de nurburgring_line.

Para el primer grabado de dataset, se leyeron los 2 topics usados para el desarrollo de la red neuronal durante 4 minutos con el siguiente comando:

```bash
timeout 240s ros2 bag record -o folderName /drone0/sensor_measurements/frontal_camera/image_raw /drone0/motion_reference/twist
```

Se pasó de nuevo de gráficas 2D a 3D.

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post12/first3dGraphic.png" alt="">
  <figcaption>First dataset graphic</figcaption>
</figure>

Los valores laterales se refieren a los valores mínimos. Por ejemplo, para el valor 5.0 en la velocidad lineal, se guardan todas las velocidades mayores a 5, siendo el máximo en la primera implementación de 6.

---
---

## Red neuronal
Para que se diera un buen entrenamiento esta vez, se necesitó aumentar el número de epochs a 30, dando la siguiente gráfica:

<figure class="align-center" style="width:60%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/post12/firstTraining.png" alt="">
  <figcaption>First training graphic</figcaption>
</figure>

Hay que tener en cuenta que los datos se pasaron crudos, sin balancear, y lo cierto es que el dron apenas era capaz de seguir la línea, por lo que primero se empezó ajustando el dataset.

---
---

## Refinamiento de la red
En este momento ya se consiguió tener la infraestructura software de la red neuronal por lo que se comenzó a refinar la misma. 


## Consideraciones futuras
Hablando con gente que ha trabajado anteriormente en redes neuronales con drones, se dio el consejo de entrenar la red neuronal con la diferencia entre 2 imágenes t y t+1 en vez de la imagen en crudo. Podría ser una técnica interesante de usar de cara al futuro.